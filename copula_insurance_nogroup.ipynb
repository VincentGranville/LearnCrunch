{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95e02344",
   "metadata": {},
   "source": [
    "<h1>Synthetizing the insurance Dataset</h1>\n",
    "<p>\n",
    "The method is based on copula. In this version, I work with the non-categorical features. No grouping is performed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24118e9c",
   "metadata": {},
   "source": [
    "<h2>Imports and Reading Dataset</h2>\n",
    "<p>\n",
    "The dataset on Kaggle, <a href=\"https://www.kaggle.com/datasets/teertha/ushealthinsurancedataset\">here</a>. \n",
    "In this notebook, I use the version on my GitHub repository,\n",
    "    <a href=\"https://github.com/VincentGranville/Main/blob/main/insurance.csv\">here</a>.\n",
    "<p>\n",
    "    <b>Features: </b>\n",
    "<ul>\n",
    "    <li>age, \n",
    "    <li>sex, \n",
    "    <li>bmi, \n",
    "    <li>children, \n",
    "    <li>smoker, \n",
    "    <li>region, \n",
    "    <li>charges. \n",
    "</ul>\n",
    "The last one is the response. Categorical fields (sex, smoker, regions) to be treated separately. Check out for \n",
    "<p>\n",
    "<ul>\n",
    "    <li>outliers, \n",
    "    <li>missing values, \n",
    "    <li>values with commas inside,\n",
    "</ul>\n",
    "and so on. Also, do we need to transform the data?\n",
    "<p>\n",
    "<b>Exercise:</b> Use dummy variables for categorical fields, and include them in the synthetization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5ec4e52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     sex     bmi  children smoker     region      charges\n",
      "0   19  female  27.900         0    yes  southwest  16884.92400\n",
      "1   18    male  33.770         1     no  southeast   1725.55230\n",
      "2   28    male  33.000         3     no  southeast   4449.46200\n",
      "3   33    male  22.705         0     no  northwest  21984.47061\n",
      "4   32    male  28.880         0     no  northwest   3866.85520\n",
      "5   31  female  25.740         0     no  southeast   3756.62160\n",
      "6   46  female  33.440         1     no  southeast   8240.58960\n",
      "7   37  female  27.740         3     no  northwest   7281.50560\n",
      "8   37    male  29.830         2     no  northeast   6406.41070\n",
      "9   60  female  25.840         0     no  northwest  28923.13692\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# copula_insurance_nogroup.py\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "\n",
    "filename = 'insurance.csv' \n",
    "data = pd.read_csv(filename)\n",
    "print(data.head(10))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9b1228",
   "metadata": {},
   "source": [
    "Now using numerical fields only: age, bmi, children, charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6975ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = data.loc[:,\"age\"]\n",
    "bmi = data.loc[:,\"bmi\"]\n",
    "children = data.loc[:,\"children\"]\n",
    "charges = data.loc[:,\"charges\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c1426a",
   "metadata": {},
   "source": [
    "<h2>Step 1: Compute correlation matrix on real data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98ba380a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.10927188 0.042469   0.29900819]\n",
      " [0.10927188 1.         0.0127589  0.19834097]\n",
      " [0.042469   0.0127589  1.         0.06799823]\n",
      " [0.29900819 0.19834097 0.06799823 1.        ]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# need correlation matrix computed on real data, for Gaussian copula\n",
    "r_data = np.stack((age, bmi, children, charges), axis = 0)\n",
    "r_corr = np.corrcoef(r_data) \n",
    "print(r_corr)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88f2186",
   "metadata": {},
   "source": [
    "Also computing the means for each feature. Not needed here, but useful to see if they make sense and get an idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faaddbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 39.21 30.66  1.09  13270\n",
      "Nobs:  1338\n"
     ]
    }
   ],
   "source": [
    "r_mu  = [np.mean(age), np.mean(bmi), np.mean(children), np.mean(charges)]\n",
    "nobs_synth = len(age)\n",
    "print(\"Mean: %5.2f %5.2f %5.2f %6.0f\" % (r_mu[0],r_mu[1],r_mu[2],r_mu[3]))\n",
    "print(\"Nobs: \",nobs_synth)\n",
    "zero = [0, 0, 0, 0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5399b61",
   "metadata": {},
   "source": [
    "<h2>Step 2: Multivariate Gaussian generation</h2>\n",
    "<p>\n",
    "Generate multivariate Gaussian with zero mean and covariance equal to correlation matrix on real data. We generate <code>nobs_synth</code> observations. In this case, the same number as in the real data.\n",
    "<p>\n",
    "First, we want to control all sources of randomness for replicability. This is done with <code>seed</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c89839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 453\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85d8202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this step to reconstruct correl structure in synth. data\n",
    "gfg = np.random.multivariate_normal(zero, r_corr, nobs_synth) \n",
    "g_age = gfg[:,0]\n",
    "g_bmi = gfg[:,1]\n",
    "g_children = gfg[:,2]\n",
    "g_charges = gfg[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041502d5",
   "metadata": {},
   "source": [
    "<h2>Step 3 and 4: From Gaussian to uniform to target distribution</h2>\n",
    "<p>\n",
    "From the correlated Gaussian with the target correlation structure, extract marginals (the features) and turn them into uniforms on [0, 1]. Then transform the uniforms into the correct target distribution: the empirical distribution of the real data, for each feature. The correlation structure is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c71307be",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = []\n",
    "\n",
    "for k in range(nobs_synth):  \n",
    "\n",
    "    # Step 3: first get uniform distrib. for each feature\n",
    "    u_age = norm.cdf(g_age[k])\n",
    "    u_bmi = norm.cdf(g_bmi[k])\n",
    "    u_children = norm.cdf(g_children[k])\n",
    "    u_charges = norm.cdf(g_charges[k])\n",
    "\n",
    "    # Step 4: turn uniform into target distrib.\n",
    "    s_age = np.quantile(age, u_age)                # synthesized age \n",
    "    s_bmi = np.quantile(bmi, u_bmi)                # synthesized bmi\n",
    "    s_children = np.quantile(children, u_children) # synthesized children\n",
    "    s_charges = np.quantile(charges, u_charges)    # synthesized charges\n",
    "    s_data.append((s_age,s_bmi,s_children, s_charges))\n",
    "\n",
    "s_data = np.array(s_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3183b285",
   "metadata": {},
   "source": [
    "<h2>Assessing Quality</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aae4b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mean Synth: 38.84 30.65  1.02  13328\n",
      "Mean Real : 39.21 30.66  1.09  13270\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_mu = np.mean(s_data, axis=0)\n",
    "print(\"\\n\")\n",
    "print(\"Mean Synth: %5.2f %5.2f %5.2f %6.0f\" % (s_mu[0],s_mu[1],s_mu[2],s_mu[3]))\n",
    "print(\"Mean Real : %5.2f %5.2f %5.2f %6.0f\" % (r_mu[0],r_mu[1],r_mu[2],r_mu[3]))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89207ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.10927188 0.042469   0.29900819]\n",
      " [0.10927188 1.         0.0127589  0.19834097]\n",
      " [0.042469   0.0127589  1.         0.06799823]\n",
      " [0.29900819 0.19834097 0.06799823 1.        ]]\n",
      "\n",
      "\n",
      "[[1.         0.09547703 0.02413221 0.28762577]\n",
      " [0.09547703 1.         0.05036735 0.15233377]\n",
      " [0.02413221 0.05036735 1.         0.05744995]\n",
      " [0.28762577 0.15233377 0.05744995 1.        ]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_corr = np.corrcoef(np.transpose(s_data))\n",
    "print(r_corr)\n",
    "print(\"\\n\")\n",
    "print(s_corr)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d4c4d6",
   "metadata": {},
   "source": [
    "<b>Exercises:</b>\n",
    "<ol>\n",
    "    <li>Check if pairwise feature scatter plots on real and synth. data are similar.\n",
    "    <li>Try with different seeds. Assess volatility of the results. Compute confidence intervals for mean age and so on.\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad1302d",
   "metadata": {},
   "source": [
    "<h2>Synthetic Data: Snapshot</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7eeab9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age        bmi  children       charges\n",
      "0  26.0  35.200000       3.0   7203.616777\n",
      "1  34.0  29.193193       2.0   9526.725877\n",
      "2  32.0  24.761289       1.0   9381.264084\n",
      "3  19.0  26.885000       2.0   3333.067695\n",
      "4  23.0  25.665819       0.0   9793.251928\n",
      "5  27.0  28.837104       3.0  21223.696804\n",
      "6  24.0  28.000000       0.0   2903.971962\n",
      "7  33.0  25.534879       0.0   6626.613634\n",
      "8  51.0  30.347082       1.0  12920.077903\n",
      "9  18.0  21.755000       1.0   4932.769237\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- np to pandas array\n",
    "s_data = pd.DataFrame(s_data, columns = ['age','bmi','children','charges'])\n",
    "print(s_data.head(10))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23b07901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     bmi  children      charges\n",
      "0  19.0  27.900       0.0  16884.92400\n",
      "1  18.0  33.770       1.0   1725.55230\n",
      "2  28.0  33.000       3.0   4449.46200\n",
      "3  33.0  22.705       0.0  21984.47061\n",
      "4  32.0  28.880       0.0   3866.85520\n",
      "5  31.0  25.740       0.0   3756.62160\n",
      "6  46.0  33.440       1.0   8240.58960\n",
      "7  37.0  27.740       3.0   7281.50560\n",
      "8  37.0  29.830       2.0   6406.41070\n",
      "9  60.0  25.840       0.0  28923.13692\n"
     ]
    }
   ],
   "source": [
    "r_data = np.transpose(r_data)\n",
    "r_data = pd.DataFrame(r_data, columns = ['age','bmi','children','charges'])\n",
    "print(r_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1036f31f",
   "metadata": {},
   "source": [
    "<h2>Gathering More Stats and Insights</h2>\n",
    "<p>\n",
    "The goal is to better compare synthetic with real data, and save summary stats for future comparison with other seeds (to assess volatility) and other methods: GAN, copula with grouping, Frank copula, copula with empirical quantiles replaced by parametric distributions fit to the real data, and feature substitution to reduce algorithmic bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6574accf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
